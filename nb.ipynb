{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9502029,"sourceType":"datasetVersion","datasetId":5782911}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n! pip install -U torch transformers datasets bitsandbytes peft huggingface_hub","metadata":{"_uuid":"cdf5602a-96bf-4a20-a11c-fc6129bd2aa3","_cell_guid":"4e888422-d4cc-4a22-bd91-d68e9ee80b6d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T20:59:55.201895Z","iopub.execute_input":"2024-09-30T20:59:55.202344Z","iopub.status.idle":"2024-09-30T21:02:48.092455Z","shell.execute_reply.started":"2024-09-30T20:59:55.202301Z","shell.execute_reply":"2024-09-30T21:02:48.091132Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"_uuid":"6b3bf6f8-138d-452b-bf2e-5b0d78db79b3","_cell_guid":"25765e1e-574d-4f72-96fa-5cc6ad139835","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's first load the model and its tokenizer\n\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n\nmodelname = 'meta-llama/Llama-3.2-3B'\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    modelname,\n    torch_dtype=torch.bfloat16, # setting default precision to bfloat16\n    device_map={\"\": 0}, # map model to cuda\n    quantization_config=BitsAndBytesConfig(\n        load_in_4bit=True, # enables 4bit quantization\n        bnb_4bit_compute_dtype=torch.bfloat16, # sets computation data type to bfloat16 for the quantization process\n        bnb_4bit_use_double_quant=True, # enables double quantization\n        bnb_4bit_quant_type='nf4', # specifying quantization type\n    )\n)\n\ntokenizer = AutoTokenizer.from_pretrained(modelname)","metadata":{"_uuid":"6fbef23f-3584-4eb0-a7a8-e957803632b6","_cell_guid":"e3a4e320-e899-4d1b-8af6-b529733649a7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:03:26.536638Z","iopub.execute_input":"2024-09-30T21:03:26.537635Z","iopub.status.idle":"2024-09-30T21:04:14.048755Z","shell.execute_reply.started":"2024-09-30T21:03:26.537591Z","shell.execute_reply":"2024-09-30T21:04:14.047711Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e263f947d56244a7afc4b2e0099e5a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"492d82e40c844745a25f1afe89aef0ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db69af9845f46b1a589d88874dc8c8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"124029c56b954c3caca71cfb47a2d4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09e487ee2aa0434c85cc0761375011ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036a9d6b027040f2866a7c51cce6a8c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2dd2ed95254bd6a06d51b0dc15ad84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"718e7f118a354b9980a1f6ccec373fb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbbc6d24faa045f6a356c0425872768a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5c54be2ad04961b39444c6bfbd44ac"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"_uuid":"2e058b05-89df-47ee-ba22-85d9ee41bd3a","_cell_guid":"e03e70b7-e4d2-4136-8df1-559f3441af7a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:14.051157Z","iopub.execute_input":"2024-09-30T21:04:14.051837Z","iopub.status.idle":"2024-09-30T21:04:14.063768Z","shell.execute_reply.started":"2024-09-30T21:04:14.051785Z","shell.execute_reply":"2024-09-30T21:04:14.062715Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from peft import LoraConfig, TaskType, get_peft_model\n\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM, # specifying the task\n    target_modules=['q_proj', 'k_proj', 'v_proj'],\n    inference_mode=False, # set up for training\n    r=16, # lora rank\n    lora_alpha=16, \n    lora_dropout=0.05,\n)\n\nmodel = get_peft_model(model, peft_config)\n\nmodel.print_trainable_parameters()","metadata":{"_uuid":"143f2aa8-be07-4db2-9b24-226c1a3c236e","_cell_guid":"775f071a-23d2-4951-b173-60cfe3e956a5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:14.065358Z","iopub.execute_input":"2024-09-30T21:04:14.065778Z","iopub.status.idle":"2024-09-30T21:04:14.573351Z","shell.execute_reply.started":"2024-09-30T21:04:14.065729Z","shell.execute_reply":"2024-09-30T21:04:14.572162Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"trainable params: 6,422,528 || all params: 3,219,172,352 || trainable%: 0.1995\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/meditations-marcus-aurelius/meditations.txt') as f:\n    data = map(lambda l: l.replace('\\n', ' '), f.read().split('\\n\\n'))\n    \ndata = [line for line in data if not line.startswith('BOOK')]\ndata[:5]","metadata":{"_uuid":"d1a82762-d716-4bcb-baef-6275808e168c","_cell_guid":"c34df46b-a1b1-46da-b648-6597c267f608","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:14.575909Z","iopub.execute_input":"2024-09-30T21:04:14.576258Z","iopub.status.idle":"2024-09-30T21:04:14.594486Z","shell.execute_reply.started":"2024-09-30T21:04:14.576220Z","shell.execute_reply":"2024-09-30T21:04:14.593498Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Provided by The Internet Classics Archive. See bottom for copyright. Available online at     http://classics.mit.edu//Antoninus/meditations.html',\n 'The Meditations By Marcus Aurelius',\n ' Translated by George Long',\n '----------------------------------------------------------------------',\n 'From my grandfather Verus I learned good morals and the government of my temper. ']"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\ndataset = Dataset.from_dict({\"text\": data})\ndataset","metadata":{"_uuid":"79c17340-83f0-4f1a-88ce-5e1da7b19aa9","_cell_guid":"27f1757d-fb9c-4eab-9d02-80f9ff22351f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:14.595584Z","iopub.execute_input":"2024-09-30T21:04:14.595903Z","iopub.status.idle":"2024-09-30T21:04:15.633396Z","shell.execute_reply.started":"2024-09-30T21:04:14.595871Z","shell.execute_reply":"2024-09-30T21:04:15.632235Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 525\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize(sample):\n    return tokenizer(\n        sample,\n        return_tensors='pt',\n        padding=True,\n        truncation=True,\n        max_length=128,\n    )\n\ntokenized_dataset = dataset.map(lambda _: tokenize(_['text']), batched=True).remove_columns('text')\ntokenized_dataset","metadata":{"_uuid":"cbe16b50-28c8-49b5-821c-9ebac3090020","_cell_guid":"a94e2b2a-215f-4736-abb2-c388112a6ed4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:15.634775Z","iopub.execute_input":"2024-09-30T21:04:15.635094Z","iopub.status.idle":"2024-09-30T21:04:16.111645Z","shell.execute_reply.started":"2024-09-30T21:04:15.635059Z","shell.execute_reply":"2024-09-30T21:04:16.110742Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/525 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e708b09aa74aa2b3259b8ab8c634bc"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask'],\n    num_rows: 525\n})"},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n\nfrom transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n\nif torch.cuda.device_count() > 1:\n    model = torch.nn.DataParallel(model)\n\ntraining_args = TrainingArguments(\n    output_dir='output',\n    remove_unused_columns=False,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate= 2e-4,\n    num_train_epochs=5,\n    fp16=True,\n    report_to='none',\n    logging_steps=20,\n)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_dataset,\n    data_collator=DataCollatorForLanguageModeling(\n        tokenizer, \n        mlm=False, \n        return_tensors='pt',\n    ),\n)","metadata":{"_uuid":"876385a8-421f-48b7-95fb-1a2d2fe39af9","_cell_guid":"c7db4a3a-77cb-4d03-be8a-f808d73955be","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:16.113167Z","iopub.execute_input":"2024-09-30T21:04:16.114216Z","iopub.status.idle":"2024-09-30T21:04:32.613902Z","shell.execute_reply.started":"2024-09-30T21:04:16.114174Z","shell.execute_reply":"2024-09-30T21:04:32.612757Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"6081aa5e-67d9-409f-97df-89c4be616fe2","_cell_guid":"9df2d52a-ef99-4d0b-ae5c-722a83178e8f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-30T21:04:32.615616Z","iopub.execute_input":"2024-09-30T21:04:32.616601Z","iopub.status.idle":"2024-09-30T21:17:25.448829Z","shell.execute_reply.started":"2024-09-30T21:04:32.616541Z","shell.execute_reply":"2024-09-30T21:17:25.447365Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [80/80 12:41, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>3.057000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.817900</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>2.723300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=80, training_loss=2.8532593607902528, metrics={'train_runtime': 771.363, 'train_samples_per_second': 3.403, 'train_steps_per_second': 0.104, 'total_flos': 5528473310330880.0, 'train_loss': 2.8532593607902528, 'epoch': 4.848484848484849})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('Llama-Aurelius')\nmodel.push_to_hub('Llama-Aurelius')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    'mrochk/Llama-Aurelius',\n    torch_dtype=torch.bfloat16, # setting default precision to bfloat16\n    device_map={\"\": 0}, # map model to cuda\n    quantization_config=BitsAndBytesConfig(\n        load_in_4bit=True, # enables 4bit quantization\n        bnb_4bit_compute_dtype=torch.bfloat16, # sets computation data type to bfloat16 for the quantization process\n        bnb_4bit_use_double_quant=True, # enables double quantization\n        bnb_4bit_quant_type='nf4', # specifying quantization type\n    )\n)\n\ndef tokenize_inf(sample): return tokenizer(sample, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:18:31.243068Z","iopub.execute_input":"2024-09-30T21:18:31.243816Z","iopub.status.idle":"2024-09-30T21:18:39.110280Z","shell.execute_reply.started":"2024-09-30T21:18:31.243772Z","shell.execute_reply":"2024-09-30T21:18:39.109169Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491759ea8ef843bda035b574c7629b28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf6a623e8024788bdae730ce334f976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/25.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62ccad66ee62400bb8aa13787dffbe20"}},"metadata":{}}]},{"cell_type":"code","source":"def inference(prompt):\n    model.eval()\n    \n    tokenized_prompt = tokenize_inf(prompt)\n    intokens = tokenized_prompt['input_ids'].to('cuda')\n    mask = tokenized_prompt['attention_mask'].to('cuda')\n\n    outokens = []\n\n    with torch.no_grad():\n        print('token', end=' ')\n        \n        for i in range(100):\n            if (i+1) % 10 == 0: print(f'{i+1}/100', end=' ')\n    \n            output = model(intokens, mask)\n            last_token_logits = output.logits[:, -1, :]\n            next_token_id = torch.argmax(last_token_logits, dim=-1).unsqueeze(0)\n            outokens.append(next_token_id.item())\n            intokens = torch.cat([intokens, next_token_id], dim=1)\n            \n        print()\n    return f'{prompt} ...{\"\".join(list(map(tokenizer.decode, outokens))).split(\".\")[0]}.'","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:26:05.547930Z","iopub.execute_input":"2024-09-30T21:26:05.548343Z","iopub.status.idle":"2024-09-30T21:26:05.557891Z","shell.execute_reply.started":"2024-09-30T21:26:05.548304Z","shell.execute_reply":"2024-09-30T21:26:05.556549Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"***Some examples of prompt:***","metadata":{}},{"cell_type":"code","source":"inference('The best thing in life is')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:26:08.901130Z","iopub.execute_input":"2024-09-30T21:26:08.902236Z","iopub.status.idle":"2024-09-30T21:26:35.025422Z","shell.execute_reply.started":"2024-09-30T21:26:08.902178Z","shell.execute_reply":"2024-09-30T21:26:35.024320Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"token 10/100 20/100 30/100 40/100 50/100 60/100 70/100 80/100 90/100 100/100 \n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'The best thing in life is... to be able to do what thou wilt, and to be able to do it at the right time.'"},"metadata":{}}]},{"cell_type":"code","source":"inference('The way of life is')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:23:46.541646Z","iopub.execute_input":"2024-09-30T21:23:46.542124Z","iopub.status.idle":"2024-09-30T21:24:12.575254Z","shell.execute_reply.started":"2024-09-30T21:23:46.542074Z","shell.execute_reply":"2024-09-30T21:24:12.574213Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"token 10/100 20/100 30/100 40/100 50/100 60/100 70/100 80/100 90/100 100/100 \n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'The way of life is ...  the way of the gods, and the way of the gods is the way of the universe.'"},"metadata":{}}]},{"cell_type":"code","source":"inference('The proper reaction against anger is')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:25:32.902816Z","iopub.execute_input":"2024-09-30T21:25:32.903155Z","iopub.status.idle":"2024-09-30T21:25:59.009557Z","shell.execute_reply.started":"2024-09-30T21:25:32.903122Z","shell.execute_reply":"2024-09-30T21:25:59.008452Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"token 10/100 20/100 30/100 40/100 50/100 60/100 70/100 80/100 90/100 100/100 \n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'The proper reaction against anger is... not to be angry.'"},"metadata":{}}]},{"cell_type":"code","source":"inference('The man who can not control his emotions')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T21:25:06.666999Z","iopub.execute_input":"2024-09-30T21:25:06.667463Z","iopub.status.idle":"2024-09-30T21:25:32.890651Z","shell.execute_reply.started":"2024-09-30T21:25:06.667402Z","shell.execute_reply":"2024-09-30T21:25:32.889640Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"token 10/100 20/100 30/100 40/100 50/100 60/100 70/100 80/100 90/100 100/100 \n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'The man who can not control his emotions ...  is like a man who has no hands.'"},"metadata":{}}]}]}